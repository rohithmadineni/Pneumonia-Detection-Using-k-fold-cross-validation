# -*- coding: utf-8 -*-
"""pneumonia 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G3oAPtiIwMxJTknLQe5oPKh2QxlVtDAk
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import seaborn as sns

# Dataset Path
dataset_path = "path_to_dataset"

# Image size for MobileNetV2
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 10  # Reduced for faster training

# Image Data Generator
datagen = ImageDataGenerator(rescale=1.0/255, validation_split=0.2)

train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training',
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation',
    shuffle=False
)

# Convert class labels to categorical (for 2 classes)
X, y = [], []

for _ in range(len(train_generator)):
    images, labels = next(train_generator)
    X.extend(images)
    y.extend(labels)

X = np.array(X)
y = np.array(y)

print(f"Data Loaded! Total Samples: {X.shape[0]}")

def build_model():
    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False  # Freeze the pre-trained layers

    # Add Custom Layers
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.3)(x)
    output_layer = Dense(1, activation='sigmoid')(x)  # Binary Classification

    model = Model(inputs=base_model.input, outputs=output_layer)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    return model

kf = KFold(n_splits=10, shuffle=True, random_state=42)
fold = 1
accuracies = []

for train_index, val_index in kf.split(X):
    print(f"\nðŸ”¹ Training Fold {fold}...")

    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]

    model = build_model()

    history = model.fit(
        X_train, y_train,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_data=(X_val, y_val),
        verbose=1
    )

    # Evaluate
    y_pred = (model.predict(X_val) > 0.5).astype("int32")
    acc = accuracy_score(y_val, y_pred)
    accuracies.append(acc)

    fold += 1

# Average Accuracy
print(f"\nâœ… Average Accuracy from 10-Fold CV: {np.mean(accuracies) * 100:.2f}%")

model.save("/content/drive/MyDrive/MobileNetV2_Final.h5")
print("âœ… Final Trained Model saved as 'MobileNetV2_Final.h5'")

plt.figure(figsize=(12, 4))

# Accuracy Graph
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Model Accuracy")
plt.legend()

# Loss Graph
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Model Loss")
plt.legend()

plt.show()

# Generate Predictions
y_pred = (model.predict(X_val) > 0.5).astype("int32")

# Confusion Matrix
cm = confusion_matrix(y_val, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Classification Report
print("ðŸ”¹ Classification Report:\n", classification_report(y_val, y_pred))
